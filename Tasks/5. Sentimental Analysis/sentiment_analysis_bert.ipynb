{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Installing package data and do the processsing"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-03-09T21:58:32.790757Z","iopub.status.busy":"2022-03-09T21:58:32.790123Z","iopub.status.idle":"2022-03-09T21:58:35.136094Z","shell.execute_reply":"2022-03-09T21:58:35.135234Z","shell.execute_reply.started":"2022-03-09T21:58:32.790659Z"},"trusted":true},"outputs":[],"source":["import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","    !nvidia-smi\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T21:58:35.139408Z","iopub.status.busy":"2022-03-09T21:58:35.139151Z","iopub.status.idle":"2022-03-09T21:59:45.382243Z","shell.execute_reply":"2022-03-09T21:59:45.381414Z","shell.execute_reply.started":"2022-03-09T21:58:35.139379Z"},"trusted":true},"outputs":[],"source":["!pip install pyarabic\n","!pip install emoji\n","!pip install pystemmer\n","!pip install optuna==2.3.0\n","!pip install transformers -U "]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T21:59:45.384266Z","iopub.status.busy":"2022-03-09T21:59:45.383968Z","iopub.status.idle":"2022-03-09T22:00:05.456103Z","shell.execute_reply":"2022-03-09T22:00:05.455293Z","shell.execute_reply.started":"2022-03-09T21:59:45.384215Z"},"trusted":true},"outputs":[],"source":["!pip install gdown"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T22:00:05.458894Z","iopub.status.busy":"2022-03-09T22:00:05.458616Z","iopub.status.idle":"2022-03-09T22:00:11.315307Z","shell.execute_reply":"2022-03-09T22:00:11.314570Z","shell.execute_reply.started":"2022-03-09T22:00:05.458858Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import pyarabic.araby as ar\n","\n","import re , emoji, Stemmer, functools, operator, string\n","import torch , gc, random, os\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, accuracy_score, f1_score\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer\n","from transformers import Trainer , TrainingArguments\n","from transformers.trainer_utils import EvaluationStrategy\n","from transformers.data.processors.utils import InputFeatures\n","from torch.utils.data import Dataset\n","\n","\n","import logging\n","\n","logging.basicConfig(level=logging.WARNING)\n","logger = logging.getLogger(__name__)"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T22:03:38.539079Z","iopub.status.busy":"2022-03-09T22:03:38.538820Z","iopub.status.idle":"2022-03-09T22:03:38.546244Z","shell.execute_reply":"2022-03-09T22:03:38.545491Z","shell.execute_reply.started":"2022-03-09T22:03:38.539050Z"},"trusted":true},"outputs":[],"source":["# REmove english words and stopping words\n","from nltk.corpus import stopwords\n","from nltk import word_tokenize\n","\n","stopwords = stopwords.words(\"arabic\")\n","\n","def remove_stopwords(text):\n","  text_tokens = word_tokenize(text)\n","\n","  tokens_without_sw = [word for word in text_tokens if not word in stopwords]\n","\n","  return \" \".join(tokens_without_sw)\n","\n","def no_english(text):\n","\ttext = re.sub(\"[a-zA-Z]+\", \"\",text)\n","\treturn text"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T22:03:38.871684Z","iopub.status.busy":"2022-03-09T22:03:38.871207Z","iopub.status.idle":"2022-03-09T22:03:38.883868Z","shell.execute_reply":"2022-03-09T22:03:38.883021Z","shell.execute_reply.started":"2022-03-09T22:03:38.871654Z"},"trusted":true},"outputs":[],"source":["# Our preprocessing to the data\n","st =  Stemmer.Stemmer('arabic')\n","def data_cleaning (text):\n","  text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n","  text = re.sub(r'^http?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n","  text = re.sub(r\"http\\S+\", \"\", text)\n","  text = re.sub(r\"https\\S+\", \"\", text)\n","  text = re.sub(r'\\s+', ' ', text)\n","  text = re.sub(\"(\\s\\d+)\",\"\",text) \n","  text = re.sub(r\"$\\d+\\W+|\\b\\d+\\b|\\W+\\d+$\", \"\", text)\n","  text = re.sub(\"\\d+\", \" \", text)\n","  text = ar.strip_tashkeel(text)\n","  text = ar.strip_tatweel(text)\n","  text = text.replace(\"#\", \" \")\n","  text = text.replace(\"@\", \" \")\n","  text = text.replace(\"_\", \" \")\n","  translator = str.maketrans('', '', string.punctuation)\n","  text = text.translate(translator)\n","  em = text\n","  em_split_emoji = emoji.get_emoji_regexp().split(em)\n","  em_split_whitespace = [substr.split() for substr in em_split_emoji]\n","  em_split = functools.reduce(operator.concat, em_split_whitespace)\n","  text = \" \".join(em_split)\n","  text = re.sub(r'(.)\\1+', r'\\1', text)\n","  text_stem = \" \".join([st.stemWord(i) for i in text.split()])\n","  text = text +\" \"+ text_stem\n","  text = text.replace(\"آ\", \"ا\")\n","  text = text.replace(\"إ\", \"ا\")\n","  text = text.replace(\"أ\", \"ا\")\n","  text = text.replace(\"ؤ\", \"و\")\n","  text = text.replace(\"ئ\", \"ي\")\n","  text = no_english(text) #remocing remaining english words\n","  text = remove_stopwords(text) #removing stopwords\n","    \n","  return text"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T22:03:39.310010Z","iopub.status.busy":"2022-03-09T22:03:39.309772Z","iopub.status.idle":"2022-03-09T22:03:48.978744Z","shell.execute_reply":"2022-03-09T22:03:48.977911Z","shell.execute_reply.started":"2022-03-09T22:03:39.309983Z"},"trusted":true},"outputs":[],"source":["#Download the data set\n","!gdown --id 1ewF8bx1KBLZTTeKWg4v5hzpo-cfHdy1O -O ./CY_data.txt"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T22:03:02.501015Z","iopub.status.busy":"2022-03-09T22:03:02.500487Z","iopub.status.idle":"2022-03-09T22:03:02.517204Z","shell.execute_reply":"2022-03-09T22:03:02.516497Z","shell.execute_reply.started":"2022-03-09T22:03:02.500977Z"},"trusted":true},"outputs":[],"source":["Test_Data_File = \"./CY_data.txt\"\n","df_cy = pd.read_csv(Test_Data_File, sep=\",\")\n","df_cy.columns = ['tweet','class']"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T22:03:03.144866Z","iopub.status.busy":"2022-03-09T22:03:03.144350Z","iopub.status.idle":"2022-03-09T22:03:03.157458Z","shell.execute_reply":"2022-03-09T22:03:03.156786Z","shell.execute_reply.started":"2022-03-09T22:03:03.144820Z"},"trusted":true},"outputs":[],"source":["#spliting the data to trian and test\n","train, test = train_test_split(df_cy, test_size=0.2, stratify=df_cy['class'])"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T22:03:48.981016Z","iopub.status.busy":"2022-03-09T22:03:48.980794Z","iopub.status.idle":"2022-03-09T22:03:50.755810Z","shell.execute_reply":"2022-03-09T22:03:50.754961Z","shell.execute_reply.started":"2022-03-09T22:03:48.980990Z"},"trusted":true},"outputs":[],"source":["# Cleaning Training Data \n","train[\"tweet\"] = train[\"tweet\"].apply(lambda x:   data_cleaning(x))\n","\n","\n","train.columns = ['tweet','class']\n","\n","train['tweet'].head(50)"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T22:04:14.356413Z","iopub.status.busy":"2022-03-09T22:04:14.355753Z","iopub.status.idle":"2022-03-09T22:04:14.363504Z","shell.execute_reply":"2022-03-09T22:04:14.362749Z","shell.execute_reply.started":"2022-03-09T22:04:14.356378Z"},"trusted":true},"outputs":[],"source":["#checking unique values.\n","train['class'].value_counts()"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T22:05:38.836698Z","iopub.status.busy":"2022-03-09T22:05:38.836250Z","iopub.status.idle":"2022-03-09T22:05:38.849494Z","shell.execute_reply":"2022-03-09T22:05:38.848394Z","shell.execute_reply.started":"2022-03-09T22:05:38.836662Z"},"trusted":true},"outputs":[],"source":["# First setting the max_len , will be useful later for BERT Model\n","Max_Len = 512\n","\n","#Spliting the Training data\n","Test_Size = 0.05 # low percentage to keep the training data as large as possible,\n","                   \n","Rand_Seed = 42 \n","\n","train_set, evaluation_set = train_test_split( train, test_size= Test_Size, random_state= Rand_Seed)\n","\n","print(\"Train set: \")\n","print(train_set[\"class\"].value_counts())\n","print(\"---------------------------\")\n","print (\"Evaluation set: \")\n","print (evaluation_set[\"class\"].value_counts())"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T22:05:50.981152Z","iopub.status.busy":"2022-03-09T22:05:50.980532Z","iopub.status.idle":"2022-03-09T22:05:51.445205Z","shell.execute_reply":"2022-03-09T22:05:51.444100Z","shell.execute_reply.started":"2022-03-09T22:05:50.981111Z"},"trusted":true},"outputs":[],"source":["Tweets_Text_Col_Test = \"tweet\"\n","\n","test_data = test\n","test_data.columns = ['tweet','class']\n","\n","test_data[Tweets_Text_Col_Test] = test_data[Tweets_Text_Col_Test].apply(lambda x:   data_cleaning(x))\n","test_data[Tweets_Text_Col_Test].head()"]},{"cell_type":"markdown","metadata":{},"source":["# Getting our model ready MARBERT."]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T22:05:56.173914Z","iopub.status.busy":"2022-03-09T22:05:56.173651Z","iopub.status.idle":"2022-03-09T22:05:56.184129Z","shell.execute_reply":"2022-03-09T22:05:56.183132Z","shell.execute_reply.started":"2022-03-09T22:05:56.173885Z"},"trusted":true},"outputs":[],"source":["Model_Used = \"UBC-NLP/MARBERT\"\n","Task_Name = \"classification\"\n","\n","# out class for the data\n","class Dataset:\n","    def __init__(\n","        self,\n","        name,\n","        train,\n","        test,\n","        label_list,\n","    ):\n","        self.name = name\n","        self.train = train\n","        self.test = test\n","        self.label_list = label_list\n","        \n","#Constructing class to get the data ready for bert\n","class BERTModelDataset(Dataset):\n","    def __init__(self, text, target, model_name, max_len, label_map):\n","      super(BERTModelDataset).__init__()\n","      self.text = text\n","      self.target = target\n","      self.tokenizer_name = model_name\n","      self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n","      self.max_len = max_len\n","      self.label_map = label_map\n","  \n","    def __len__(self):\n","      return len(self.text)\n","\n","    def __getitem__(self,item):\n","      text = str(self.text[item])\n","      text = \" \".join(text.split())\n","    \n","      encoded_review = self.tokenizer(\n","      text,\n","      max_length= self.max_len,\n","      add_special_tokens= True,\n","      return_token_type_ids=False,\n","      pad_to_max_length=True,\n","      truncation='longest_first',\n","      return_attention_mask=True,\n","      return_tensors='pt',\n","      \n","    )\n","      input_ids = encoded_review['input_ids'].to(device)\n","      attention_mask = encoded_review['attention_mask'].to(device)\n","\n","      return InputFeatures(input_ids=input_ids.flatten(), attention_mask=attention_mask.flatten(), label=self.label_map[self.target[item]])"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T22:05:57.295755Z","iopub.status.busy":"2022-03-09T22:05:57.295208Z","iopub.status.idle":"2022-03-09T22:05:57.303118Z","shell.execute_reply":"2022-03-09T22:05:57.302458Z","shell.execute_reply.started":"2022-03-09T22:05:57.295722Z"},"trusted":true},"outputs":[],"source":["# Init model\n","def model_init():\n","  return AutoModelForSequenceClassification.from_pretrained(Model_Used, return_dict=True, num_labels=len(label_map))\n","\n","# our metrics\n","def compute_metrics(p): \n","  preds = np.argmax(p.predictions, axis=1)\n","  assert len(preds) == len(p.label_ids)\n","  print(classification_report(p.label_ids,preds))\n","  weighted_f1 = f1_score(p.label_ids,preds,average='weighted')\n","  acc = accuracy_score(p.label_ids,preds)\n","  return {\n","      'macro_f1' : weighted_f1,\n","      'accuracy': acc\n","  }\n","\n","#setting the seed to reproduce\n","def set_seed(seed):\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T22:05:58.082340Z","iopub.status.busy":"2022-03-09T22:05:58.081802Z","iopub.status.idle":"2022-03-09T22:06:08.077763Z","shell.execute_reply":"2022-03-09T22:06:08.076985Z","shell.execute_reply.started":"2022-03-09T22:05:58.082302Z"},"trusted":true},"outputs":[],"source":["label_list = list(train_set[Tweets_Sentiment_Col_Train].unique())\n","\n","print(label_list)\n","print(train_set[Tweets_Sentiment_Col_Train].value_counts())\n","\n","data_set = Dataset( \"KAUST\", train_set, evaluation_set, label_list )\n","\n","#maping our labels to int\n","label_map = { v:index for index, v in enumerate(label_list) }\n","print(label_map)\n","\n","\n","# passing the data to out model\n","train_dataset = BERTModelDataset(train_set[Tweets_Text_Col_Train].to_list(),\n","                                 train_set[Tweets_Sentiment_Col_Train].to_list(),Model_Used,Max_Len,label_map)\n","\n","evaluation_dataset = BERTModelDataset(evaluation_set[Tweets_Text_Col_Train].to_list(),\n","                                      evaluation_set[Tweets_Sentiment_Col_Train].to_list(),Model_Used,Max_Len,label_map)"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T22:06:12.628512Z","iopub.status.busy":"2022-03-09T22:06:12.627767Z","iopub.status.idle":"2022-03-09T22:06:12.637644Z","shell.execute_reply":"2022-03-09T22:06:12.636819Z","shell.execute_reply.started":"2022-03-09T22:06:12.628463Z"},"trusted":true},"outputs":[],"source":["#define training arguments\n","training_args = TrainingArguments(\"./train\")\n","training_args.lr_scheduler_type = 'cosine'\n","training_args.evaluate_during_training = True\n","training_args.adam_epsilon =1e-8 \n","training_args.learning_rate = 5e-05 \n","training_args.fp16 = True\n","training_args.per_device_train_batch_size = 16 #64 \n","training_args.per_device_eval_batch_size = 16 # 64 \n","training_args.gradient_accumulation_steps = 2\n","training_args.num_train_epochs= 10\n","training_args.warmup_steps = 500 \n","training_args.evaluation_strategy = EvaluationStrategy.EPOCH\n","training_args.logging_steps = 200\n","training_args.save_steps = 100000 \n","training_args.seed = 50\n","training_args.disable_tqdm = False"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T22:06:14.029659Z","iopub.status.busy":"2022-03-09T22:06:14.028979Z","iopub.status.idle":"2022-03-09T22:06:38.184739Z","shell.execute_reply":"2022-03-09T22:06:38.183861Z","shell.execute_reply.started":"2022-03-09T22:06:14.029621Z"},"trusted":true},"outputs":[],"source":["# passing all to trainer\n","training_args.dataloader_pin_memory = False\n","gc.collect()\n","torch.cuda.empty_cache()\n","set_seed(Rand_Seed) \n","\n","trainer = Trainer(\n","    model = model_init(),\n","    args = training_args,\n","    train_dataset = train_dataset,\n","    eval_dataset= evaluation_dataset,\n","    compute_metrics=compute_metrics\n",")\n","\n","print(training_args.seed)"]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T22:06:43.801175Z","iopub.status.busy":"2022-03-09T22:06:43.800872Z","iopub.status.idle":"2022-03-09T22:27:25.457459Z","shell.execute_reply":"2022-03-09T22:27:25.455930Z","shell.execute_reply.started":"2022-03-09T22:06:43.801125Z"},"trusted":true},"outputs":[],"source":["#Train\n","trainer.train()"]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T22:31:43.105904Z","iopub.status.busy":"2022-03-09T22:31:43.105648Z","iopub.status.idle":"2022-03-09T22:31:59.543647Z","shell.execute_reply":"2022-03-09T22:31:59.542902Z","shell.execute_reply.started":"2022-03-09T22:31:43.105875Z"},"trusted":true},"outputs":[],"source":["#prediction fucntion\n","def predict(text, tokenizer):\n"," \n","  encoded_review = tokenizer.encode_plus(\n","    text,\n","    max_length=Max_Len,\n","    add_special_tokens=True,\n","    return_token_type_ids=False,\n","    pad_to_max_length=True, #True,\n","    truncation='longest_first',\n","    return_attention_mask=True,\n","    return_tensors='pt'\n","  )\n","\n","  input_ids = encoded_review['input_ids'].to(device) #(input_ids + ([tokenizer.pad_token_id] * padding_length)).to(device)  \n","  attention_mask = encoded_review['attention_mask'].to(device)\n","    \n","\n","  output = trainer.model(input_ids, attention_mask)\n","  _, prediction = torch.max(output[0], dim=1)\n","  return prediction[0]\n","\n","#then lets play !\n","\n","tokenizer = AutoTokenizer.from_pretrained(Model_Used)\n","\n","prediction_list = []\n","i = 0\n","for tweet in test_data[Tweets_Text_Col_Test]:\n","  \n","    pre = predict(tweet,tokenizer)\n","    pre_txt = label_list[pre]\n","    \n","    prediction_list.append(pre_txt)\n","    \n","    i = i + 1"]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T22:31:59.575918Z","iopub.status.busy":"2022-03-09T22:31:59.575654Z","iopub.status.idle":"2022-03-09T22:31:59.580982Z","shell.execute_reply":"2022-03-09T22:31:59.580223Z","shell.execute_reply.started":"2022-03-09T22:31:59.575884Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import accuracy_score"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T22:31:59.582737Z","iopub.status.busy":"2022-03-09T22:31:59.582129Z","iopub.status.idle":"2022-03-09T22:31:59.592852Z","shell.execute_reply":"2022-03-09T22:31:59.592059Z","shell.execute_reply.started":"2022-03-09T22:31:59.582700Z"},"trusted":true},"outputs":[],"source":["accuracy_score(prediction_list, test_data['class'])"]},{"cell_type":"markdown","metadata":{},"source":["# Here we got 73% with ten epoch we may get a higher accuracy with a longer training period."]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
