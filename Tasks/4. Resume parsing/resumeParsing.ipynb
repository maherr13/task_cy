{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "id": "tiVBq5A81QXX",
        "outputId": "c4529ea9-462b-4e64-a317-adc5542a238d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.7/dist-packages (20211012)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.7/dist-packages (from pdfminer.six) (36.0.1)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from pdfminer.six) (3.0.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography->pdfminer.six) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography->pdfminer.six) (2.21)\n",
            "Collecting doc2text\n",
            "  Downloading doc2text-0.2.4.tar.gz (21 kB)\n",
            "Collecting PyPDF2\n",
            "  Downloading PyPDF2-1.26.0.tar.gz (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from doc2text) (1.21.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from doc2text) (7.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from doc2text) (1.4.1)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.9-py2.py3-none-any.whl (14 kB)\n",
            "Collecting mime\n",
            "  Downloading mime-0.1.0.tar.gz (32 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from mime->doc2text) (0.16.0)\n",
            "Collecting Pillow\n",
            "  Downloading Pillow-9.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 47.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from pytesseract->doc2text) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=21.3->pytesseract->doc2text) (3.0.7)\n",
            "Building wheels for collected packages: doc2text, mime, PyPDF2\n",
            "  Building wheel for doc2text (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for doc2text: filename=doc2text-0.2.4-py2.py3-none-any.whl size=8424 sha256=5cfb273fe65d7974f1015ae9d06bc335b108c140d56e388249f64ddc756f808b\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/81/95/e2120a7dd5316154d15614457d1b1cca0dc6c0eec232ce23a4\n",
            "  Building wheel for mime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mime: filename=mime-0.1.0-py3-none-any.whl size=39042 sha256=e043974a65d5ed7c29cf163891c79d5acdff30ce6ef0a6936ae159cc7d6787c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/08/ca/e4b63a36aa89eb1c7ebb73976f42e9adf81dca5e02d4557b0f\n",
            "  Building wheel for PyPDF2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyPDF2: filename=PyPDF2-1.26.0-py3-none-any.whl size=61102 sha256=1d6e109ab4c2f9ead10e5803635258509c774e00ced2555fa192685153b10d83\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1a/24/648467ade3a77ed20f35cfd2badd32134e96dd25ca811e64b3\n",
            "Successfully built doc2text mime PyPDF2\n",
            "Installing collected packages: Pillow, pytesseract, PyPDF2, mime, doc2text\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Pillow-9.0.1 PyPDF2-1.26.0 doc2text-0.2.4 mime-0.1.0 pytesseract-0.3.9\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#importing packages to deal with pdf and docs extensions.\n",
        "!pip install pdfminer.six\n",
        "!pip install doc2text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plQ7DrmxGHr8"
      },
      "outputs": [],
      "source": [
        "#these functions for reading pdf and docs files and return text variable\n",
        "\n",
        "\n",
        "from pdfminer.converter import TextConverter\n",
        "from pdfminer.pdfinterp import PDFPageInterpreter\n",
        "from pdfminer.pdfinterp import PDFResourceManager\n",
        "from pdfminer.layout import LAParams\n",
        "from pdfminer.pdfpage import PDFPage\n",
        "import io\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    with open(pdf_path, 'rb') as fh:\n",
        "        # iterate over all pages of PDF document\n",
        "        for page in PDFPage.get_pages(fh, caching=True, check_extractable=True):\n",
        "            # creating a resoure manager\n",
        "            resource_manager = PDFResourceManager()\n",
        "            \n",
        "            # create a file handle\n",
        "            fake_file_handle = io.StringIO()\n",
        "            \n",
        "            # creating a text converter object\n",
        "            converter = TextConverter(\n",
        "                                resource_manager, \n",
        "                                fake_file_handle, \n",
        "                                codec='utf-8', \n",
        "                                laparams=LAParams()\n",
        "                        )\n",
        "\n",
        "            # creating a page interpreter\n",
        "            page_interpreter = PDFPageInterpreter(\n",
        "                                resource_manager, \n",
        "                                converter\n",
        "                            )\n",
        "\n",
        "            # process current page\n",
        "            page_interpreter.process_page(page)\n",
        "            \n",
        "            # extract text\n",
        "            text = fake_file_handle.getvalue()\n",
        "            yield text\n",
        "\n",
        "            # close open handles\n",
        "            converter.close()\n",
        "            fake_file_handle.close()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWhJZaFGG-XV",
        "outputId": "eece95b1-62ac-4dcf-ae75-dc0ae74a1f09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.63.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.11.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 19.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.21.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.63.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.9.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.11.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "#installing spacy and languages.\n",
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCvWuAIoHoHe"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "# load pre-trained model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# initialize matcher with a vocab\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "#extracting names from the text\n",
        "def getName(resume_text):\n",
        "    nlp_text = nlp(resume_text)\n",
        "    \n",
        "    # First name and Last name are always Proper Nouns\n",
        "    pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
        "    \n",
        "    matcher.add('NAME', None, pattern)\n",
        "    \n",
        "    matches = matcher(nlp_text)\n",
        "    \n",
        "    for match_id, start, end in matches:\n",
        "        span = nlp_text[start:end]\n",
        "        return span.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loomjfIjHvVX"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def getMobile(text):\n",
        "    phone = re.findall(re.compile(r'(?:(?:\\+?([1-9]|[0-9][0-9]|[0-9][0-9][0-9])\\s*(?:[.-]\\s*)?)?(?:\\(\\s*([2-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9])\\s*\\)|([0-9][1-9]|[0-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9]))\\s*(?:[.-]\\s*)?)?([2-9]1[02-9]|[2-9][02-9]1|[2-9][02-9]{2})\\s*(?:[.-]\\s*)?([0-9]{4})(?:\\s*(?:#|x\\.?|ext\\.?|extension)\\s*(\\d+))?'), text)\n",
        "    \n",
        "    if phone:\n",
        "        number = ''.join(phone[0])\n",
        "        if len(number) > 10:\n",
        "            return '+' + number\n",
        "        else:\n",
        "            return number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlJTLQA_H1R1"
      },
      "outputs": [],
      "source": [
        "#extracting email from the text.\n",
        "import re\n",
        "\n",
        "def getEmail(email):\n",
        "    email = re.findall(\"([^@|\\s]+@[^@]+\\.[^@|\\s]+)\", email)\n",
        "    if email:\n",
        "        try:\n",
        "            return email[0].split()[0].strip(';')\n",
        "        except IndexError:\n",
        "            return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bogrJuPGH4mp"
      },
      "outputs": [],
      "source": [
        "#extracting skills from the text\n",
        "import pandas as pd\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "\n",
        "def getSkills(resume_text):\n",
        "    nlp_text = nlp(resume_text)\n",
        "\n",
        "    # removing stop words and implementing word tokenization\n",
        "    tokens = [token.text for token in nlp_text if not token.is_stop]\n",
        "    \n",
        "    # reading cs that contains skills \n",
        "    data = pd.read_csv(\"skills.csv\") \n",
        "    noun_chunks = nlp_text.noun_chunks\n",
        "    # extract extract the skills\n",
        "    skills = list(data.columns.values)\n",
        "    \n",
        "    skillset = []\n",
        "    \n",
        "    # getting one-gram skills (example: java)\n",
        "    for token in tokens:\n",
        "        if token.lower() in skills:\n",
        "            skillset.append(token)\n",
        "    \n",
        "    # getting bi-grams and tri-grams (example: computer vision)\n",
        "    for token in noun_chunks:\n",
        "        token = token.text.lower().strip()\n",
        "        if token in skills:\n",
        "            skillset.append(token)\n",
        "    \n",
        "    return [i.capitalize() for i in set([i.lower() for i in skillset])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20V0j2LoH-5S",
        "outputId": "9fb4d522-dfd3-4aff-d5e6-4fc8fe3f1531"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "/bin/bash: -c: line 0: syntax error near unexpected token `('\n",
            "/bin/bash: -c: line 0: `python -m nltk nltk.download('words')'\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk\n",
        "!python -m nltk nltk.download('words')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkTSK_RZIdm8",
        "outputId": "ef1ea551-8e09-4dab-a287-9f2799df074e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# extracting education\n",
        "import re\n",
        "import spacy\n",
        "from nltk.corpus import stopwords\n",
        "import nltk \n",
        "import re\n",
        "\n",
        "# load pre-trained model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "nltk.download(\"words\")\n",
        "nltk.download(\"stopwords\")\n",
        "# Grad all general stop words\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "# Education Degrees\n",
        "EDUCATION = [\n",
        "            'BE','B.E.', 'B.E', 'BS', 'B.S',\n",
        "            'ME', 'M.E', 'M.E.', 'MS', 'M.S', \n",
        "            'BTECH', 'B.TECH', 'M.TECH', 'MTECH', \n",
        "            'SSC', 'HSC', 'CBSE', 'ICSE', 'X', 'XII'\n",
        "        ]\n",
        "\n",
        "def getEducation(resume_text):\n",
        "    nlp_text = nlp(resume_text)\n",
        "\n",
        "    # Sentence Tokenizer\n",
        "    nlp_text = [sent.string.strip() for sent in nlp_text.sents]\n",
        "\n",
        "    edu = {}\n",
        "    # Extract education degree\n",
        "    for index, text in enumerate(nlp_text):\n",
        "        for tex in text.split():\n",
        "            # Replace all special symbols\n",
        "            tex = re.sub(r'[?|$|.|!|,]', r'', tex)\n",
        "            if tex.upper() in EDUCATION and tex not in STOPWORDS:\n",
        "                edu[tex] = text + nlp_text[index + 1]\n",
        "\n",
        "\n",
        "    \n",
        "   \n",
        "\n",
        "    # Extract year\n",
        "    education = []\n",
        "    for key in edu.keys():\n",
        "        year = re.search(re.compile(r'(((20|19)(\\d{2})))'), edu[key])\n",
        "        if year:\n",
        "            education.append((key, ''.join(year[0])))\n",
        "        else:\n",
        "            education.append(key)\n",
        "\n",
        "    word = 'Bachelor'\n",
        "    regexp = re.compile(r'(?=.*\\Bachelor\\b)')\n",
        "    if regexp.search(resume_text):\n",
        "      education.append(word)\n",
        "\n",
        "\n",
        "    return education"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xmz7KcWLzbAv"
      },
      "source": [
        "## Testing Cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gr28PN_O3W2X"
      },
      "outputs": [],
      "source": [
        "cv1 = \"\"\n",
        "# getting the data from the CV\n",
        "for page in extract_text_from_pdf(\"/content/cv1.pdf\"):\n",
        "    cv1 += ' ' + page"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6PqBqcO3Wff"
      },
      "outputs": [],
      "source": [
        "cv2 = \"\"\n",
        "# getting the data from the CV\n",
        "for page in extract_text_from_pdf(\"/content/cv2.pdf\"):\n",
        "    cv2 += ' ' + page"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBoL1SoR3kPH"
      },
      "outputs": [],
      "source": [
        "#forming data representing the person\n",
        "data1 = {\"name\" : getName(cv1), \n",
        "        \"email\" : getEmail(cv1),\n",
        "        \"number\" : getMobile(cv1),\n",
        "        \"education\" : getEducation(cv1),\n",
        "        \"skills\" : getSkills(cv1)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnord0AP3m2G"
      },
      "outputs": [],
      "source": [
        "#forming data representing the person\n",
        "data2 = {\"name\" : getName(cv2), \n",
        "        \"email\" : getEmail(cv2),\n",
        "        \"number\" : getMobile(cv2),\n",
        "        \"education\" : getEducation(cv2),\n",
        "        \"skills\" : getSkills(cv2)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2D7Yxesxvlv"
      },
      "outputs": [],
      "source": [
        "#Job Requirements.\n",
        "skillsRequired = ['Python', 'Pandas', \"Keras\", \"Mathematics\", \"Nltk\", \"Machine learning\", \"Sql\"]\n",
        "education = [ 'BS', 'B.S', 'MS', 'M.S', 'Bachelor']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6I8fexenYPxd"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "The criteria for passing the screen can be specified\n",
        "the criteria here is to have ratio of the skills upto 70%\n",
        "\"\"\"\n",
        "\n",
        "def isGood(dic):\n",
        "  for edu in dic['education']:\n",
        "    if edu in education:\n",
        "\n",
        "      acquired = set.intersection(set(skillsRequired), set(dic['skills']))\n",
        "      ratio = len(acquired) / len(skillsRequired)\n",
        "      print(\"the ratio of skills acquired : \", ratio)\n",
        "      if ratio >0.7:\n",
        "        return True\n",
        "\n",
        "    \n",
        "  return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0l2lvMTy1VDS",
        "outputId": "4c2311be-6607-46ca-d679-e1c01c37b276"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the ratio of skills acquired :  0.2857142857142857\n",
            "The candidate Mahmoud Salama failed\n"
          ]
        }
      ],
      "source": [
        "if isGood(data1):\n",
        "  print(f\"The candidate {getName(cv1)} passed\")\n",
        "else:\n",
        "  print(f\"The candidate {getName(cv1)} failed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0UNxG5I1W0b",
        "outputId": "b207b526-7951-4f74-a3ca-3be818340605"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the ratio of skills acquired :  0.7142857142857143\n",
            "The candidate Muhammed Mamdouh passed\n"
          ]
        }
      ],
      "source": [
        "if isGood(data2):\n",
        "  print(f\"The candidate {getName(cv2)} passed\")\n",
        "else:\n",
        "  print(f\"The candidate {getName(cv2)} failed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSGKE_z2CTak",
        "outputId": "e339208f-8c32-4026-c585-73c5fb9bf42f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'education': ['Bachelor'],\n",
              " 'email': 'mahmoudsalama748@yahoo.com',\n",
              " 'name': 'Mahmoud Salama',\n",
              " 'number': '+01276020003',\n",
              " 'skills': ['English',\n",
              "  'Spark',\n",
              "  'System',\n",
              "  'Sql',\n",
              "  'Github',\n",
              "  'Workflow',\n",
              "  'C++',\n",
              "  'Java',\n",
              "  'Segmentation',\n",
              "  'Research',\n",
              "  'Communication',\n",
              "  'Ai',\n",
              "  'Cloud',\n",
              "  'Coding',\n",
              "  'Gis',\n",
              "  'Technical',\n",
              "  'Training',\n",
              "  'Tensorflow',\n",
              "  'Analysis',\n",
              "  'Aws',\n",
              "  'Email',\n",
              "  'Python',\n",
              "  'Engineering',\n",
              "  'Shell',\n",
              "  'Presentation',\n",
              "  'Supervisor']}"
            ]
          },
          "execution_count": 217,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#sample of the Data extracted\n",
        "\n",
        "data1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ke_vf5cWDvIL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "resumeParsing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
