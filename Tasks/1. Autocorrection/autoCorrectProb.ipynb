{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autoCorrect_prob.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Installing packages"
      ],
      "metadata": {
        "id": "hTg2I_JSWa8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CApCvGTLtB6o",
        "outputId": "c2a58641-5373-4c8a-8207-0dfd24f8aef0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jA7woaJqs1CG"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# downloadind text\n",
        "nltk.download('gutenberg')\n",
        "emma = nltk.Text(nltk.corpus.gutenberg.words('austen-emma.txt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHe8Lk1wtDc2",
        "outputId": "78b81750-fe1e-4a0e-a1fb-2ac840b2dcdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Exracting words from the list\n",
        "emma = [element for element in emma if element.isalpha()]"
      ],
      "metadata": {
        "id": "aZMaR2Dw6xAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#count how many each word appeared\n",
        "from collections import Counter\n",
        "\n",
        "def get_count(words):\n",
        "    \n",
        "    word_count_dict = {} \n",
        "    word_count_dict = Counter(words)  \n",
        "    return word_count_dict"
      ],
      "metadata": {
        "id": "R9CJ-Ppt7kLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dictionary with the count corresponding to the words\n",
        "word_count = get_count(emma)"
      ],
      "metadata": {
        "id": "2N4Alarm8a7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating the prob for each word to appear\n",
        "def calc_prob(word_count_dict):\n",
        "    probs = {}\n",
        "    m = sum(word_count_dict.values())\n",
        "    for key in word_count_dict.keys():\n",
        "        probs[key] = word_count_dict[key] / m\n",
        "    return probs"
      ],
      "metadata": {
        "id": "GDYI_B5t8dNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probabilities = calc_prob(word_count)"
      ],
      "metadata": {
        "id": "7oiTnxH7DkUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#forming the vocab\n",
        "vocab = set(emma)"
      ],
      "metadata": {
        "id": "pwVj3__TDpfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#probablistic model"
      ],
      "metadata": {
        "id": "p2kUZrQAEBUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#making each word an instance of class word that have value(text) and probabilty\n",
        "class Word:\n",
        "  def __init__(self, val, prob):\n",
        "    self.val = val\n",
        "    self.prob = prob\n",
        "\n",
        "words = []\n",
        "for key, value in probabilities.items():\n",
        "  words.append(Word(key, value))"
      ],
      "metadata": {
        "id": "nG0LvmgsKpEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#transforming the instance to list of text\n",
        "def get_text(words):\n",
        "  gwords = []\n",
        "  for word in words:\n",
        "    gwords.append(word.val)\n",
        "\n",
        "\n",
        "  return gwords"
      ],
      "metadata": {
        "id": "p0EPrvmxOxAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#a function that suggests words to the mistaken words\n",
        "def suggest(dist):\n",
        "  suggestions = []\n",
        "  if len(dist[0]) > 0:\n",
        "    dist[0].sort(key= lambda word : word.prob, reverse=True)\n",
        "    suggestions = [dist[0][i] for i in range(len(dist[0]))]\n",
        "    \n",
        "    return get_text(suggestions)\n",
        "\n",
        "  elif len(dist[1]) > 0:\n",
        "    dist[1].sort(key= lambda word : word.prob, reverse=True)\n",
        "    suggestions = [dist[1][i] for i in range(len(dist[1]))]\n",
        "    \n",
        "    return get_text(suggestions)\n",
        "\n",
        "  else:\n",
        "\n",
        "    dist[2].sort(key= lambda word : word.prob, reverse=True)\n",
        "    suggestions = [dist[2][i] for i in range(3)]\n",
        "    \n",
        "    return get_text(suggestions)\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "o6h_naGbMQ4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function that calculates the leve distance between a word and all the vocab\n",
        "def getDist(mistake, words):\n",
        "  \n",
        "  dist_1 = []\n",
        "  dist_2 = []\n",
        "  dist_3 = []\n",
        "\n",
        "  for word in words:\n",
        "    dst = nltk.edit_distance(word.val, mistake)\n",
        "    if dst == 1:\n",
        "      dist_1.append(word)\n",
        "\n",
        "    if dst == 2:\n",
        "      dist_2.append(word)\n",
        "\n",
        "    if dst == 3:\n",
        "      dist_3.append(word)\n",
        "\n",
        "  return dist_1, dist_2, dist_3"
      ],
      "metadata": {
        "id": "7VHcNOwrSHjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function that correct the mistaken words\n",
        "def Correct(text):\n",
        "  suggests = {}\n",
        "  incorrect = []\n",
        "  text = text.strip().split()\n",
        "  for word in text:\n",
        "    if word in vocab:\n",
        "      continue\n",
        "\n",
        "    else:\n",
        "      incorrect.append(word)\n",
        "\n",
        "  for bword in incorrect:\n",
        "    suggests[bword] = suggest(getDist(bword, words))\n",
        "\n",
        "  return suggests\n"
      ],
      "metadata": {
        "id": "K0eq-ojoPhD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#test cases"
      ],
      "metadata": {
        "id": "ucDjaZZTX-6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I do nt kno howw to write\"\n",
        "\n",
        "print(Correct(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0np4DfCRwiG",
        "outputId": "011f360b-69ab-446b-c97b-fd44930e8202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'nt': ['it', 'not', 'at', 'no', 'It', 'At', 't', 'St'], 'kno': ['no', 'know'], 'howw': ['how', 'hows']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"thi iss a hannd craftted auto corect\"\n",
        "print(Correct(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3ijsykNR80Y",
        "outputId": "0de44262-6142-453c-db49-43e41b41112b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'thi': ['the', 'this', 'thin'], 'iss': ['is', 'Miss', 'its', 'miss'], 'hannd': ['hand'], 'craftted': ['chatted'], 'auto': ['to', 'but', 'at', 'But', 'out', 'into', 'put', 'aunt', 'ago', 'also', 'duty', 'cut', 'act', 'apt', 'acute', 'ate', 'art', 'mute', 'Put', 'author'], 'corect': ['correct']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"thi est cas is the lst cse\"\n",
        "\n",
        "print(Correct(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTq9sUrKYMke",
        "outputId": "f2f0b17c-4776-4b92-b17e-d270edc795fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'thi': ['the', 'this', 'thin'], 'est': ['best', 'rest', 'eat', 'lest', 'West', 'east'], 'cas': ['was', 'as', 'can', 'has', 'case', 'Was', 'Has', 'cast', 'caps', 'car'], 'lst': ['last', 'let', 'lost', 'list', 'lest', 'lot'], 'cse': ['use', 'case', 'se']}\n"
          ]
        }
      ]
    }
  ]
}